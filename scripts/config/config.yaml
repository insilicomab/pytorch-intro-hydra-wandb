# Hydra Settings
defaults: 
  - _self_ 
  - override hydra/hydra_logging: disabled 
  - override hydra/job_logging: disabled
 
hydra:
  run:
    dir: ./
  output_subdir: null
  sweep:
    dir: .
    subdir: .


# User setting
img_dir: '/content/drive/MyDrive/Colab Notebooks/cifar10/input/train_images'
df_dir: '/content/drive/MyDrive/Colab Notebooks/cifar10/input/train_master.tsv'
model_name: ${model.name}
load_model: 'convnext_base.pth'
num_classes: 10


# wandb
wandb:
  project: pytorch-intro-hydra-wandb
  run_name: ''
  tags: []
  notes: ''
  data_dir: ${img_dir}
  model_name: ${model.name}
  

# train.py
save_model_path: '/content/drive/MyDrive/Colab Notebooks/cifar10/model/'
train_master: '/content/drive/MyDrive/Colab Notebooks/cifar10/input/train_master.tsv'
split:
  test_size: 0.25
  random_state: 42
transform:
  image_size: 96
  randomhorizontalflip:
    p: 0.2
  randomrotation:
    degrees: 20
  randomaffine:
    degrees: [-10, 10]
    translate: [0.1, 0.1]
    scale: [0.5, 1.5]
  colorjitter:
    brightness: 0.5
    contrast: 0.5
    saturation: 0.5
  normalize: 
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
dataset:
  tr_img_path: '/content/drive/MyDrive/Colab Notebooks/cifar10/input/train_images'
  test_img_path: '/content/drive/MyDrive/Colab Notebooks/cifar10/input/test_images'
dataloader:
  tr_batch_size: 64
  val_batch_size: 64
  test_batcu_size: 1
model:
  name: 'convnext_base'
  pretrained: True
  num_classes: ${num_classes}
optimizer:
  lr: 1e-3
  weight_decay: 0.0001
earlystopping:
  patience: 20
  verbose: 1 # True (1), False (0)
schedular:
  mode: 'max'
  factor: 0.5
  patience: 5
  min_lr: 1e-5
  verbose: True
train:
  epochs: 50
  model_name: 'convnext_base'


# inference.py
wandb_run_path: 'insilicomab/pytorch-intro-hydra-wandb/1lp10jnj'
test_master: '/content/drive/MyDrive/Colab Notebooks/cifar10/input/sample_submit.tsv'
submit_path: '/content/drive/MyDrive/Colab Notebooks/cifar10/submit/'
submit_name: 'sample_submission.tsv'
